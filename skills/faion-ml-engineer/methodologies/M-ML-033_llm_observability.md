---
id: M-ML-033
name: "LLM Management and Observability"
domain: ML
skill: faion-ml-engineer
category: "best-practices-2026"
---

## M-ML-033: LLM Management and Observability

### Problem

No visibility into LLM cost, quality, and reliability.

### Solution: LLMOps Platform

**Key Metrics:**

| Category | Metrics |
|----------|---------|
| Cost | Tokens/request, cost/conversation, budget tracking |
| Quality | Response relevance, hallucination rate, user satisfaction |
| Performance | Latency (P50, P95, P99), throughput |
| Reliability | Error rate, retry rate, fallback frequency |

**Observability Stack:**
```
Application -> Tracing (Langfuse/Helicone) -> Dashboard
                    |
              Prompt Registry -> Version Control
                    |
              Evaluation Suite -> Quality Gates
```

**Tools:**
| Tool | Focus |
|------|-------|
| Langfuse | Open-source tracing, prompts |
| Helicone | Cost analytics, caching |
| Weights & Biases | Experiment tracking |
| Arize Phoenix | Evaluation, embeddings |
| Portkey | Gateway, fallbacks |

**Best Practices:**
- Track every LLM call
- Version control prompts
- Set up cost alerts
- A/B test prompt changes
- Monitor for drift
