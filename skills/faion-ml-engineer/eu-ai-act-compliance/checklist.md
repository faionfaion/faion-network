# EU AI Act Compliance Checklist

Actionable compliance checklist organized by role and deadline.

## Phase 1: February 2025 (Completed)

### Prohibited Practices

- [x] Review all AI systems for prohibited practices
- [x] Remove social scoring systems
- [x] Remove emotion recognition in workplace/education
- [x] Remove manipulative AI targeting vulnerable groups
- [x] Remove real-time remote biometric identification (unless exempted)

### AI Literacy

- [x] Train staff on AI capabilities and limitations
- [x] Document AI competency requirements by role
- [x] Establish AI governance awareness program

## Phase 2: August 2025 (Active)

### GPAI Model Providers

- [ ] Prepare technical documentation for GPAI models
- [ ] Create model cards with capabilities/limitations
- [ ] Document training data sources and types
- [ ] Publish training data summary
- [ ] Implement copyright compliance measures
- [ ] Respect robots.txt and opt-out mechanisms
- [ ] Prepare transparency reports

### GPAI with Systemic Risk

- [ ] Conduct model evaluations (red-teaming)
- [ ] Assess systemic risks
- [ ] Track and report serious incidents
- [ ] Ensure cybersecurity protections
- [ ] Report compute used for training

## Phase 3: August 2026 (Planning)

### All Organizations

- [ ] Complete AI system inventory
- [ ] Classify each system by risk level
- [ ] Establish AI governance framework
- [ ] Designate compliance roles

### High-Risk AI System Providers

#### Risk Management (Article 9)

- [ ] Implement risk management system
- [ ] Document known/foreseeable risks
- [ ] Estimate risks from intended use
- [ ] Estimate risks from reasonably foreseeable misuse
- [ ] Establish risk mitigation measures
- [ ] Test for residual risks

#### Data Governance (Article 10)

- [ ] Document training data practices
- [ ] Ensure data quality standards
- [ ] Address bias in datasets
- [ ] Implement data governance procedures
- [ ] Verify lawful data collection

#### Technical Documentation (Article 11)

- [ ] Create system description
- [ ] Document design specifications
- [ ] Describe development process
- [ ] Detail monitoring capabilities
- [ ] Include testing results

#### Record-Keeping (Article 12)

- [ ] Enable automatic event logging
- [ ] Ensure logs are traceable
- [ ] Store logs for appropriate period
- [ ] Protect log integrity

#### Transparency (Article 13)

- [ ] Provide clear instructions for use
- [ ] Disclose AI system capabilities
- [ ] Document limitations
- [ ] Specify intended purpose

#### Human Oversight (Article 14)

- [ ] Design for human oversight capability
- [ ] Enable human intervention
- [ ] Allow human override
- [ ] Provide oversight training

#### Accuracy, Robustness, Cybersecurity (Article 15)

- [ ] Achieve appropriate accuracy levels
- [ ] Implement robustness measures
- [ ] Address adversarial attacks
- [ ] Ensure cybersecurity controls

#### Quality Management System (Article 17)

- [ ] Establish compliance strategy
- [ ] Document design processes
- [ ] Implement testing procedures
- [ ] Define corrective actions
- [ ] Create audit procedures

#### Conformity Assessment (Article 43)

- [ ] Determine assessment type (self/third-party)
- [ ] Conduct conformity assessment
- [ ] Prepare EU declaration of conformity
- [ ] Obtain CE marking (where applicable)

#### EU Database Registration (Article 71)

- [ ] Register in EU AI database
- [ ] Keep registration updated
- [ ] Include required information

### High-Risk AI System Deployers

- [ ] Verify provider compliance
- [ ] Implement human oversight measures
- [ ] Monitor AI system operation
- [ ] Report malfunctions to provider
- [ ] Conduct fundamental rights impact assessment (where required)
- [ ] Inform workers of AI use
- [ ] Inform affected individuals

### Limited Risk AI Systems (Article 50)

#### Chatbots and AI Interaction

- [ ] Disclose AI nature to users
- [ ] Make disclosure clear and timely
- [ ] Allow human request option

#### Emotion Recognition / Biometric Categorization

- [ ] Inform subjects of system use
- [ ] Obtain consent where required
- [ ] Process data lawfully under GDPR

#### Deepfakes and Synthetic Content

- [ ] Label AI-generated content
- [ ] Add machine-readable watermarks
- [ ] Enable content authenticity verification

## Ongoing Compliance

### Monitoring

- [ ] Track AI system performance
- [ ] Monitor for drift and degradation
- [ ] Review incident reports
- [ ] Update risk assessments

### Documentation Maintenance

- [ ] Keep technical docs current
- [ ] Update model cards
- [ ] Refresh training data summaries
- [ ] Maintain audit trails

### Incident Management

- [ ] Establish incident reporting process
- [ ] Define severity thresholds
- [ ] Report serious incidents to authorities
- [ ] Document corrective actions

## Compliance by Role

### For Providers

| Responsibility | Deadline |
|----------------|----------|
| GPAI documentation | Aug 2025 |
| High-risk compliance | Aug 2026 |
| Conformity assessment | Aug 2026 |
| EU database registration | Aug 2026 |
| Post-market monitoring | Ongoing |

### For Deployers

| Responsibility | Deadline |
|----------------|----------|
| Verify provider compliance | Aug 2026 |
| Human oversight | Aug 2026 |
| Worker notification | Aug 2026 |
| Fundamental rights assessment | Aug 2026 |
| Operational monitoring | Ongoing |

### For Importers/Distributors

| Responsibility | Deadline |
|----------------|----------|
| Verify CE marking | Aug 2026 |
| Check documentation | Aug 2026 |
| Maintain traceability | Aug 2026 |

---

*ML Engineer Methodology - faion-network*
