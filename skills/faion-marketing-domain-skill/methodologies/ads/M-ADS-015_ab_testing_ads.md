# M-ADS-015: A/B Testing Ads

## Metadata

| Field | Value |
|-------|-------|
| **ID** | M-ADS-015 |
| **Name** | A/B Testing Ads |
| **Category** | Ads API |
| **Difficulty** | Intermediate |
| **Agent** | faion-ads-agent |
| **Related** | M-GRO-004, M-ADS-003, M-MKT-024 |

---

## Problem

You're running ads but not learning. Each campaign is a guess. You don't know if your blue button beats red, or if testimonials outperform product shots. Without testing, you can't improve systematically.

A/B testing ads means making data-driven decisions instead of guessing.

---

## Framework

Ad testing follows the scientific method:

```
HYPOTHESIZE -> What do you think will work better?
TEST        -> Run controlled experiment
ANALYZE     -> Was the difference significant?
APPLY       -> Implement learnings at scale
```

### Step 1: What to Test

**Testing priority (highest impact first):**

| Element | Impact | Test Frequency |
|---------|--------|----------------|
| **Offer** | Highest | Monthly |
| **Hook/headline** | Very high | Bi-weekly |
| **Creative type** | High | Monthly |
| **Visual style** | Medium | Monthly |
| **Copy length** | Medium | As needed |
| **CTA** | Medium | Quarterly |
| **Colors** | Low | Rarely |

**Test one thing at a time.**
If you change hook AND visual, you won't know which caused the difference.

### Step 2: Set Up Proper Tests

**Test structure:**

```
Campaign: [Name] - A/B Test
├── Ad Set (same targeting)
│   ├── Ad A: Control (current best)
│   └── Ad B: Variant (one change)
```

**Requirements for valid tests:**

| Requirement | Why |
|-------------|-----|
| Same audience | Isolate creative variable |
| Same budget split | Equal opportunity |
| Sufficient sample | Statistical significance |
| Enough time | Account for variance |

**Minimum sample sizes:**
- CTR testing: 1,000+ impressions per variant
- Conversion testing: 100+ conversions per variant
- Use a [sample size calculator](https://www.optimizely.com/sample-size-calculator/)

### Step 3: Calculate Statistical Significance

**Why significance matters:**
- Random chance can create fake winners
- Need 95% confidence minimum
- Don't stop tests early

**Quick significance check:**

| Metric | Variance | Significance |
|--------|----------|--------------|
| CTR: 1.0% vs 1.2% | +20% | Maybe (need more data) |
| CTR: 1.0% vs 1.5% | +50% | Likely significant |
| CTR: 1.0% vs 2.0% | +100% | Almost certainly significant |

**Use tools:**
- Platform built-in significance
- Online calculators
- Statistical formulas

### Step 4: Meta A/B Testing

**Meta's built-in testing:**

1. Go to Experiments
2. Create A/B test
3. Select variable to test
4. Set test duration and budget
5. Let Meta determine winner

**What Meta can test:**
- Audiences
- Creatives
- Placements
- Optimization goals

**When to use Meta's testing:**
- Budget allows ($200+ per variant)
- Want platform-managed test
- Testing audiences or placements

### Step 5: Google Ads Testing

**Google's testing options:**

**Ad variations (Experiments):**
1. Campaigns → Experiments
2. Create ad variation
3. Set percentage of traffic
4. Set duration
5. Apply winner

**Manual testing:**
- Multiple ads per ad group
- Let Google rotate equally (at first)
- Review after sufficient data
- Pause losers

### Step 6: Build a Testing Roadmap

**Monthly testing plan:**

| Week | Test Focus | Hypothesis |
|------|------------|------------|
| 1 | Hook A vs B | Emotional hook beats rational |
| 2 | Continue + analyze | - |
| 3 | Visual A vs B | UGC beats polished |
| 4 | Continue + analyze | - |

**Learning library:**
Document every test result to build institutional knowledge.

---

## Templates

### A/B Test Brief

```markdown
## Test: [Name]

### Hypothesis
We believe [variant] will outperform [control] because [reasoning].

### Variables
- **Control:** [Current approach]
- **Variant:** [New approach]
- **Changed element:** [Specific change]
- **Held constant:** [Everything else]

### Success Metric
- Primary: [CTR / Conversions / CPA]
- Secondary: [Supporting metric]

### Test Parameters
- Platform: [Meta / Google / etc.]
- Audience: [Same for both]
- Budget: $[X] per variant
- Duration: [X] days
- Required sample: [X] [impressions/conversions]

### Expected Outcome
- Current baseline: [X%]
- Minimum detectable effect: [Y%]
- Expected winner: [Variant / Unsure]
```

### Test Results Template

```markdown
## Test Results: [Name]

### Summary
- **Winner:** [Control / Variant / Inconclusive]
- **Confidence:** [X%]
- **Lift:** [+/- X%]

### Data
| Metric | Control | Variant | Difference |
|--------|---------|---------|------------|
| Impressions | X | X | - |
| Clicks | X | X | +X% |
| CTR | X% | X% | +X% |
| Conversions | X | X | +X% |
| CPA | $X | $X | -X% |

### Statistical Significance
- Confidence level: [X%]
- [Significant / Not significant]

### Learnings
- [What we learned]
- [Why we think this happened]

### Next Steps
- [ ] Implement winner at scale
- [ ] Test next hypothesis: [Description]
```

### Testing Roadmap

```markdown
## Q[X] Testing Roadmap

### Month 1
| Week | Test | Status |
|------|------|--------|
| 1-2 | Hook: Problem vs Benefit | Planned |
| 3-4 | Visual: Photo vs Video | Planned |

### Month 2
| Week | Test | Status |
|------|------|--------|
| 1-2 | Offer: 7-day vs 14-day trial | Planned |
| 3-4 | CTA: Learn More vs Start Free | Planned |

### Month 3
| Week | Test | Status |
|------|------|--------|
| 1-2 | Format: Carousel vs Single | Planned |
| 3-4 | Iterate on winners | Planned |

### Test Backlog
- [ ] Testimonial vs product demo
- [ ] Long copy vs short copy
- [ ] Before/after vs feature focus
```

---

## Examples

### Example 1: Hook Test

**Hypothesis:** Question hook will beat statement hook

**Control:**
```
"Manage projects effortlessly with our tool"
```

**Variant:**
```
"Still tracking projects in spreadsheets?"
```

**Results:**
- Control CTR: 0.8%
- Variant CTR: 1.4%
- Lift: +75%
- Significance: 99%

**Learning:** Question hooks drive more curiosity and clicks.

### Example 2: Visual Test

**Hypothesis:** UGC-style video will outperform polished video

**Control:** Professional product demo
**Variant:** Phone-recorded customer testimonial

**Results:**
- Control CPA: $45
- Variant CPA: $32
- Lift: -29% (better)
- Significance: 97%

**Learning:** Authentic content resonates more than polished. Incorporate more UGC.

---

## Implementation Checklist

### Before Testing
- [ ] Define hypothesis
- [ ] Choose one variable to test
- [ ] Calculate required sample size
- [ ] Document control and variant

### During Testing
- [ ] Ensure equal budget split
- [ ] Don't peek too early
- [ ] Monitor for errors
- [ ] Wait for significance

### After Testing
- [ ] Calculate significance
- [ ] Document results
- [ ] Implement winner
- [ ] Plan next test

---

## Common Mistakes

| Mistake | Why It Fails | Fix |
|---------|--------------|-----|
| Testing too many things | Can't isolate cause | One variable |
| Stopping early | False positives | Wait for significance |
| Too small sample | Unreliable results | Calculate minimum |
| No hypothesis | Random testing | Start with belief |
| Not documenting | Lost learnings | Record everything |
| Never implementing | Wasted effort | Apply winners |

---

## Statistical Guidelines

| Situation | Recommendation |
|-----------|----------------|
| Low traffic | Test higher-impact elements |
| High traffic | Can test smaller changes |
| Close results | Run longer, need more data |
| Clear winner | Stop and implement |

**Minimum confidence levels:**
- 95% for major decisions
- 90% for directional learning
- 80% for quick iterations

---

## Tools

| Purpose | Tools |
|---------|-------|
| Meta testing | Experiments tool |
| Google testing | Experiments, ad variations |
| Significance | Calculators (VWO, Optimizely) |
| Documentation | Notion, spreadsheet |
| Analysis | Platform analytics |

---

## Related Methodologies

- **M-GRO-004:** A/B Testing Framework (general testing)
- **M-ADS-003:** Meta Creative (what to test)
- **M-MKT-024:** Conversion Optimization (landing page tests)
- **M-ADS-007:** Google Creative (ad copy testing)

---

*Methodology M-ADS-015 | Ads API | faion-ads-agent*
