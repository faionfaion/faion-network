# LLM Prompts for Mistake Analysis

Prompts for analyzing, documenting, and preventing mistakes using LLM assistance.

## Mistake Capture Prompts

### Initial Incident Analysis

```
Analyze this incident and help me document it:

**What happened:**
[Paste error logs, screenshots, or description]

**Context:**
[What was being done when the error occurred]

Please provide:
1. Incident summary (2-3 sentences)
2. Severity assessment (Critical/High/Medium/Low) with reasoning
3. Category classification
4. Immediate impact assessment
5. Suggested timeline reconstruction questions
```

### Root Cause Analysis

```
Help me perform root cause analysis using the Five Whys method.

**Incident:** [Brief description]
**Immediate symptom:** [What was observed]

For each "why", probe deeper into the cause. Stop when you reach a systemic or process-level root cause that can be addressed.

Format:
1. Why [symptom]? → [Answer]
   Analysis: [Why this matters]

2. Why [Answer 1]? → [Answer]
   Analysis: [Why this matters]

[Continue until root cause]

**Root Cause:** [Final statement]
**Systemic factors:** [List any process/tooling gaps]
```

### LLM-Specific Error Analysis

```
Analyze this LLM-generated error:

**Task given to LLM:**
[Original prompt or task description]

**LLM output (problematic):**
```
[Paste the incorrect code/text]
```

**Expected output:**
```
[What should have been generated]
```

**Error type:** [hallucination / context loss / instruction drift / other]

Analyze:
1. What specific error did the LLM make?
2. What in the context might have caused this?
3. Were there warning signs that could have been caught?
4. What additional context would have prevented this?
5. What verification step would have caught this?
6. Recommended prompt/context improvements
```

## Prevention Planning Prompts

### Generate Prevention Rules

```
Based on this mistake, suggest automated prevention rules:

**Mistake ID:** MIS_XXXX_XXX
**Category:** [category]
**What happened:** [description]
**Root cause:** [root cause]

Generate prevention rules in this format:

```json
{
  "id": "PREV_XXX",
  "trigger": {
    "type": "[file_pattern|task_keyword|code_pattern]",
    "config": {}
  },
  "action": {
    "type": "[warn|require_checklist|block]",
    "message": "Include mistake ID reference"
  }
}
```

Consider:
1. What patterns could detect this before it happens?
2. What file types or paths are affected?
3. What keywords indicate risk?
4. What automated checks could prevent this?
```

### Generate Checklist Items

```
Based on this mistake, suggest checklist additions:

**Mistake:** [description]
**Category:** [category]
**Root cause:** [root cause]

Generate checklist items for:
1. Pre-task checklist (before starting similar work)
2. During-task checklist (verification steps)
3. Post-task checklist (validation before completion)

Format:
- [ ] [Checklist item] (position: first/middle/last)
  - Prevents: [what this prevents]
  - Source: MIS_XXXX_XXX
```

### Multi-Model Review Prompt

```
Review this code/output generated by another AI model:

**Original task:**
[What was requested]

**Generated output:**
```
[Paste code or text to review]
```

Review for:
1. **Correctness:** Does it actually do what was requested?
2. **Hallucinations:** Are there any non-existent APIs, methods, or features?
3. **Edge cases:** What inputs/scenarios aren't handled?
4. **Error handling:** Are all failure paths covered?
5. **Security:** Any obvious vulnerabilities?
6. **Best practices:** Does it follow standard patterns?

For each issue found, provide:
- Severity: Critical/High/Medium/Low
- Location: Line number or section
- Issue: What's wrong
- Fix: How to correct it
```

## Learning and Pattern Recognition

### Extract Learning Patterns

```
Analyze these recent mistakes and identify patterns:

**Mistakes:**
1. MIS_XXX: [Brief description]
2. MIS_YYY: [Brief description]
3. MIS_ZZZ: [Brief description]

Identify:
1. **Common themes:** What do these mistakes have in common?
2. **Root cause patterns:** Are there recurring systemic issues?
3. **High-risk areas:** What types of tasks need extra attention?
4. **Missing safeguards:** What process gaps are these revealing?
5. **Recommended focus areas:** What should we prioritize improving?

Format findings as actionable recommendations with specific examples.
```

### Predict Potential Mistakes

```
Based on this task description, identify potential mistakes to watch for:

**Task:**
[Task description]

**Technologies involved:**
[List of technologies, frameworks, APIs]

**Similar past mistakes:**
[List relevant mistake IDs if known]

Analyze:
1. What are the high-risk areas in this task?
2. What LLM-specific errors might occur?
3. What verification steps are critical?
4. What context should be included in prompts?
5. What checklists should be followed?

Format as a pre-task warning checklist.
```

## Context Improvement Prompts

### Optimize Context for Task

```
Help optimize the LLM context for this task to prevent errors:

**Task type:** [code generation / refactoring / bug fix / etc.]
**Technologies:** [list]
**Known issues to prevent:** [list relevant mistake IDs]

Current context includes:
[List what's currently in context]

Recommend:
1. What essential documentation should be included?
2. What examples would help?
3. What constraints should be explicitly stated?
4. What warning should be injected based on past mistakes?
5. Is the task appropriately scoped for single context?

Prioritize recommendations by importance for error prevention.
```

### Generate Warning Injection

```
Based on these relevant mistakes, generate a warning to inject into LLM context:

**Relevant mistakes:**
- MIS_XXX: [Brief description]
- MIS_YYY: [Brief description]

**Current task:**
[Task description]

Generate a concise warning block (max 200 words) that:
1. Alerts to specific risks
2. References relevant mistake IDs
3. Provides concrete prevention steps
4. Doesn't overwhelm context with detail

Format:
```
## Warning: [Risk Area]
Based on past mistakes (MIS_XXX, MIS_YYY), watch for:
- [Specific risk 1]
- [Specific risk 2]

Prevention:
- [ ] [Step 1]
- [ ] [Step 2]
```
```

## Post-Mortem Prompts

### Generate Post-Mortem Report

```
Help generate a post-mortem report for this incident:

**Incident summary:**
[What happened]

**Timeline:**
[Key events with timestamps]

**Impact:**
[Users affected, downtime, cost]

**Root cause analysis:**
[Five whys results]

Generate a complete post-mortem report including:
1. Executive summary
2. Impact assessment
3. Timeline
4. Root cause analysis
5. Contributing factors
6. Resolution steps taken
7. Prevention measures
8. Action items with owners
9. Lessons learned

Follow blameless post-mortem principles.
```

### Review Prevention Effectiveness

```
Review the effectiveness of this prevention rule:

**Rule:** PREV_XXX
**Source mistake:** MIS_XXXX_XXX
**Implementation date:** YYYY-MM-DD

**Statistics:**
- Times triggered: N
- Times prevented: N
- False positives: N

Analyze:
1. Is the rule effective? (prevented/triggered ratio)
2. Are there false positive issues?
3. Should the trigger be adjusted?
4. Are there gaps this rule doesn't cover?
5. Recommendations for improvement

If ineffective, suggest alternative approaches.
```

## Self-Correction Loop Prompts

### Request Self-Review

```
Before I accept your output, please self-review:

**Your output:**
[Paste LLM output]

**Original requirements:**
[What was requested]

Self-check:
1. Does your output fully meet the requirements?
2. Are there any assumptions you made that should be validated?
3. What parts are you least confident about?
4. What edge cases might not be handled?
5. What could go wrong when this is used?

Be critical and highlight any concerns, even if minor.
```

### Iterative Correction

```
Your previous output had this error:

**Error:**
[Description of what went wrong]

**Error evidence:**
[Logs, test output, or description]

Please:
1. Acknowledge what went wrong
2. Explain why the error occurred
3. Provide corrected output
4. Explain what you changed and why
5. Identify if similar errors might exist elsewhere in your output

Do not repeat the same error pattern.
```

## Usage Notes

1. **Always provide context** - Include relevant code, logs, and requirements
2. **Be specific** - Vague prompts lead to vague analysis
3. **Request structured output** - Ask for specific formats for consistency
4. **Iterate** - Use follow-up prompts to dig deeper
5. **Verify** - Don't blindly accept LLM analysis, especially for root causes
6. **Document** - Save useful prompt/response pairs for future reference
