# Local Llm Ollama - LLM Prompts

## Code Generation Prompt

```
Create a Python implementation for Local LLM deployment with Ollama.

Requirements:
- installation
- model management
- API usage
- optimization

Include error handling, logging, and tests.
```

## Code Review Prompt

```
Review this Local LLM deployment with Ollama implementation for:
- Code quality
- Error handling
- Performance
- Security
- Best practices
```

## Debugging Prompt

```
Debug this error in Local LLM deployment with Ollama implementation:

ERROR: {{error_message}}
CODE: {{code_snippet}}

Provide:
1. Root cause analysis
2. Fix with explanation
3. Prevention strategy
```
