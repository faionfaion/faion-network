# Multimodal VUI Design

## Problem

Voice-only interfaces lack visual feedback and complex data display.

## Multimodal Patterns

| Pattern | Use Case |
|---------|----------|
| Voice-initiated, screen-completed | Search results, selections |
| Screen-initiated, voice-completed | Form filling |
| Voice + visual feedback | Confirmations, progress |
| Voice navigation + visual content | Information browsing |

## Smart Display Design

**Voice input:** "Show me recipes for pasta"

**Visual output:**
- Card carousel with images
- Spoken summary: "I found 5 pasta recipes"
- Tap to expand, voice to navigate

## Fallback Strategy

- Primary: Voice interaction
- Secondary: Touch/tap alternatives
- Tertiary: Keyboard input

Always provide multiple input modes.

## Sources

- [Multimodal Design Patterns - Google](https://designguidelines.withgoogle.com/conversation/multimodal/)
- [Amazon Echo Show Design Guide](https://developer.amazon.com/en-US/docs/alexa/alexa-presentation-language/apl-overview.html)
- [Voice + Screen Best Practices](https://www.nngroup.com/articles/multimodal-voice/)
- [Designing Multimodal Experiences](https://www.smashingmagazine.com/2025/multimodal-design/)
- [Smart Display UX](https://www.interaction-design.org/literature/article/multimodal-vui)
