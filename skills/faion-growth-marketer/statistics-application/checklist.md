# Checklist - Applied Statistics in Experiments

## Test Design

- [ ] Define hypothesis clearly
- [ ] Set primary metric to test
- [ ] Calculate required sample size
- [ ] Determine test duration
- [ ] Plan traffic allocation (typically 50/50)
- [ ] Document test plan

## Baseline Metrics

- [ ] Measure control group metrics
- [ ] Document baseline conversion rate
- [ ] Record baseline value
- [ ] Understand baseline variance
- [ ] Plan for seasonal effects
- [ ] Document external factors

## Running the Experiment

- [ ] Launch test with proper sample size
- [ ] Maintain traffic allocation
- [ ] Avoid peeking at results
- [ ] Monitor for data collection issues
- [ ] Track test duration
- [ ] Document any anomalies

## Intermediate Analysis

- [ ] Check test progress
- [ ] Monitor sample size accumulation
- [ ] Verify data quality
- [ ] Look for obvious issues
- [ ] Don't make early decisions
- [ ] Continue until statistical power achieved

## Statistical Analysis

- [ ] Calculate variant conversion rate
- [ ] Calculate lift (percentage improvement)
- [ ] Determine p-value
- [ ] Calculate confidence interval
- [ ] Verify statistical significance (p < 0.05)
- [ ] Check effect size (lift %)

## Multiple Hypothesis Testing

- [ ] Understand multiple comparison problem
- [ ] Adjust significance level (Bonferroni)
- [ ] Focus on primary metric
- [ ] Limit secondary metrics
- [ ] Interpret secondary metrics cautiously
- [ ] Document hypothesis priority

## Results Interpretation

- [ ] Determine if winner is statistically significant
- [ ] Calculate practical significance
- [ ] Consider lift magnitude
- [ ] Review confidence interval width
- [ ] Check for data anomalies
- [ ] Make win/lose decision

## Post-Test Analysis

- [ ] Segment results by user type
- [ ] Analyze heterogeneous treatment effects
- [ ] Look for interaction effects
- [ ] Document surprising findings
- [ ] Plan follow-up tests
- [ ] Communicate results clearly