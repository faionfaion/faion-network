---
id: llm-cost-basics
name: "LLM Cost Basics"
domain: ML
skill: faion-ml-engineer
category: "ml-engineering"
---

# LLM Cost Basics

Understanding LLM API costs, tracking usage, model pricing, and basic optimization for production applications.

## When to Use

- Starting new LLM projects
- Budget planning
- Cost analysis
- Model selection decisions

## Model Pricing Comparison (2024-2025)

| Model | Input (per 1M) | Output (per 1M) | Context |
|-------|----------------|-----------------|---------|
| GPT-4o | $5.00 | $15.00 | 128K |
| GPT-4o-mini | $0.15 | $0.60 | 128K |
| GPT-3.5-turbo | $0.50 | $1.50 | 16K |
| Claude 3.5 Sonnet | $3.00 | $15.00 | 200K |
| Claude 3 Haiku | $0.25 | $1.25 | 200K |
| Gemini 1.5 Pro | $3.50 | $10.50 | 1M |
| Gemini 1.5 Flash | $0.075 | $0.30 | 1M |

## Cost Tracking

```python
from dataclasses import dataclass
from typing import Dict
from datetime import datetime

@dataclass
class ModelPricing:
    input_per_1m: float
    output_per_1m: float

PRICING = {
    "gpt-4o": ModelPricing(5.00, 15.00),
    "gpt-4o-mini": ModelPricing(0.15, 0.60),
    "gpt-4-turbo": ModelPricing(10.00, 30.00),
    "gpt-3.5-turbo": ModelPricing(0.50, 1.50),
    "claude-3-5-sonnet-20241022": ModelPricing(3.00, 15.00),
    "claude-3-haiku-20240307": ModelPricing(0.25, 1.25),
}

class CostTracker:
    """Track and analyze LLM API costs."""

    def __init__(self):
        self.calls = []
        self.total_cost = 0.0
        self.total_input_tokens = 0
        self.total_output_tokens = 0

    def record(self, model: str, input_tokens: int, output_tokens: int, metadata: Dict = None):
        """Record an API call."""
        pricing = PRICING.get(model)
        if not pricing:
            cost = 0.0
        else:
            cost = (
                (input_tokens / 1_000_000) * pricing.input_per_1m +
                (output_tokens / 1_000_000) * pricing.output_per_1m
            )

        self.calls.append({
            "timestamp": datetime.now().isoformat(),
            "model": model,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "cost": cost,
            "metadata": metadata or {}
        })

        self.total_cost += cost
        self.total_input_tokens += input_tokens
        self.total_output_tokens += output_tokens

    def get_summary(self) -> Dict:
        """Get cost summary."""
        by_model = {}
        for call in self.calls:
            model = call["model"]
            if model not in by_model:
                by_model[model] = {"calls": 0, "cost": 0.0, "tokens": 0}
            by_model[model]["calls"] += 1
            by_model[model]["cost"] += call["cost"]
            by_model[model]["tokens"] += call["input_tokens"] + call["output_tokens"]

        return {
            "total_cost": self.total_cost,
            "total_calls": len(self.calls),
            "total_input_tokens": self.total_input_tokens,
            "total_output_tokens": self.total_output_tokens,
            "by_model": by_model,
            "avg_cost_per_call": self.total_cost / len(self.calls) if self.calls else 0
        }

class CostAwareClient:
    """OpenAI client wrapper with cost tracking."""

    def __init__(self, client, tracker: CostTracker = None):
        self.client = client
        self.tracker = tracker or CostTracker()

    def chat_complete(self, **kwargs) -> Dict:
        """Make API call and track cost."""
        response = self.client.chat.completions.create(**kwargs)

        self.tracker.record(
            model=kwargs.get("model", "unknown"),
            input_tokens=response.usage.prompt_tokens,
            output_tokens=response.usage.completion_tokens,
            metadata={"function": "chat_complete"}
        )

        return response
```

## Model Routing

```python
from enum import Enum
from dataclasses import dataclass
from typing import Optional

class TaskComplexity(Enum):
    SIMPLE = "simple"
    MEDIUM = "medium"
    COMPLEX = "complex"

@dataclass
class ModelConfig:
    name: str
    max_tokens: int
    cost_per_1k_input: float
    cost_per_1k_output: float
    capabilities: list

class ModelRouter:
    """Route requests to appropriate models based on task complexity."""

    def __init__(self):
        self.models = {
            TaskComplexity.SIMPLE: ModelConfig(
                name="gpt-4o-mini",
                max_tokens=16384,
                cost_per_1k_input=0.00015,
                cost_per_1k_output=0.0006,
                capabilities=["chat", "simple_reasoning"]
            ),
            TaskComplexity.MEDIUM: ModelConfig(
                name="gpt-4o",
                max_tokens=4096,
                cost_per_1k_input=0.005,
                cost_per_1k_output=0.015,
                capabilities=["chat", "reasoning", "code"]
            ),
            TaskComplexity.COMPLEX: ModelConfig(
                name="gpt-4-turbo",
                max_tokens=4096,
                cost_per_1k_input=0.01,
                cost_per_1k_output=0.03,
                capabilities=["chat", "complex_reasoning", "code", "analysis"]
            )
        }

    def classify_complexity(self, prompt: str) -> TaskComplexity:
        """Classify task complexity heuristically."""
        prompt_lower = prompt.lower()

        simple_indicators = ["translate", "summarize briefly", "yes or no", "list", "define", "what is"]
        complex_indicators = ["analyze", "compare and contrast", "write code", "debug", "explain in detail",
                              "step by step", "multiple perspectives", "evaluate"]

        simple_score = sum(1 for ind in simple_indicators if ind in prompt_lower)
        complex_score = sum(1 for ind in complex_indicators if ind in prompt_lower)

        if complex_score >= 2 or len(prompt) > 2000:
            return TaskComplexity.COMPLEX
        elif simple_score >= 2 or len(prompt) < 200:
            return TaskComplexity.SIMPLE
        else:
            return TaskComplexity.MEDIUM

    def get_model(self, prompt: str, force_complexity: Optional[TaskComplexity] = None) -> str:
        """Get appropriate model for the task."""
        complexity = force_complexity or self.classify_complexity(prompt)
        return self.models[complexity].name

    def estimate_cost(self, prompt: str, estimated_output_tokens: int = 500) -> Dict:
        """Estimate cost for different model options."""
        import tiktoken
        encoding = tiktoken.get_encoding("cl100k_base")
        input_tokens = len(encoding.encode(prompt))

        estimates = {}
        for complexity, config in self.models.items():
            cost = (
                (input_tokens / 1000) * config.cost_per_1k_input +
                (estimated_output_tokens / 1000) * config.cost_per_1k_output
            )
            estimates[complexity.value] = {
                "model": config.name,
                "cost": cost,
                "input_tokens": input_tokens
            }

        return estimates
```

## Best Practices

1. **Model Selection** - Start with cheapest model that works, use routing for mixed workloads, reserve expensive models for complex tasks
2. **Cost Tracking** - Track cost per feature/endpoint, set budget alerts, analyze token usage patterns
3. **Token Awareness** - Output tokens cost more than input, long context = higher costs, count tokens before API calls
4. **Budget Planning** - Set daily/monthly limits, monitor usage in real-time, plan for spikes

## Common Pitfalls

1. **Wrong Model** - Using expensive models for simple tasks
2. **No Monitoring** - Surprise bills at month end
3. **Ignoring Output Tokens** - They cost more than input
4. **No Budget Limits** - Runaway costs in production

## Sources

- [OpenAI Pricing](https://openai.com/pricing)
- [Anthropic Pricing](https://www.anthropic.com/pricing)
- [Google AI Pricing](https://ai.google.dev/pricing)
- [tiktoken Library](https://github.com/openai/tiktoken)
- [OpenAI Cost Management](https://platform.openai.com/docs/guides/production-best-practices/managing-costs)
